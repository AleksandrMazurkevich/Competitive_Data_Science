{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "# Что такое W&B?\n",
    "\n",
    "`Weights & Biases (W&B)` - это многофункциональная платформа для отслеживания экспериментов, логирования результатов, которая позволяет облегчить и ускорить рутинные процессы при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ключевые особенности\n",
    "\n",
    "* Позволяет отслеживать показатели работы модели в режиме реального времени и сразу же выявляйте проблемные места.\n",
    "* Визуализация результатов - графики, изображения, видео, аудио, 3D-объекты и многое [другое](https://docs.wandb.ai/guides/track/log#logging-objects).\n",
    "* Позволяет тренировать модели с разных устройств и хранить результаты в одном месте, так же удобно при командной работе над задачей\n",
    "* Использование артефактов W&B позволяет отслеживать и создавать версии ваших наборов данных, моделей, зависимостей и результатов в конвейерах машинного обучения.\n",
    "* Низкий порог входа (можно начать с 6 строк кода), так же есть готовые интеграции со всеми популярными DS фреймворками\n",
    "\n",
    "![centralized dashboard](https://i.imgur.com/BGgfZj3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка `wandb`\n",
    "\n",
    "`wandb` (библиотека W&B), по умолчанию установлена на Kagglе\n",
    "\n",
    "Поскольку образ kaggle не часто обновляется, а `wandb` постоянно выпускает новые версии,рекомендуется установить последнюю версию с помощью флага `--upgrade`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регистрация учетной записи и вход в систему\n",
    "\n",
    "Вам понадобится уникальный ключ API для входа в Weights & Biases.\n",
    "\n",
    "1. Если у вас нет учетной записи Weights & Biases, вы можете перейти на https://wandb.ai/site и создать БЕСПЛАТНУЮ учетную запись.\n",
    "2. Доступ к ключу API: https://wandb.ai/authorize.\n",
    "\n",
    "На Kaggle можно авторизоваться в W&B двумя способами:\n",
    "\n",
    "1. С помощью `wandb.login ()`. Он запросит ключ API, который вы можете скопировать + вставить.\n",
    "2. Используя Kaggle secrets для хранения ключа API и использовать приведенный ниже фрагмент кода для входа в систему. Прочтите это [обсуждение](https://www.kaggle.com/product-feedback/114053), чтобы узнать больше о Kaggle secrets.\n",
    "\n",
    "```python\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "wandb_api = user_secrets.get_secret(\"wandb_api\") \n",
    "wandb.login(key=wandb_api)\n",
    "```\n",
    "[Подробнее о входе в W&B](https://docs.wandb.ai/ref/cli/wandb-login)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Возьмем, для примера, реализацию `MLP` из раздела про нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загружаем файлы датасета\n",
    "\n",
    "car_info = pd.read_csv('../data/car_info.csv')   # car_info - информация про машины с таргетом\n",
    " \n",
    "rides_info = pd.read_csv('../data/rides_info.csv') # rides_info - информация про поездки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_info = rides_info.merge(car_info, on = 'car_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_cols = ['user_id', 'car_id', 'ride_id', 'ride_date']\n",
    "cat_cols = ['car_type', 'fuel_type', 'model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# закодируем категориальные фичи в one hot encoding вектора\n",
    "rides_info = pd.get_dummies(rides_info, columns=cat_cols)\n",
    "\n",
    "# заполним пропущенные значения медианным значением по столбцу\n",
    "rides_info.fillna(rides_info.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_df = rides_info.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# переведем строковые значения категориального таргета в целочисленные\n",
    "le = LabelEncoder()\n",
    "rides_df['target_class'] = le.fit_transform(rides_df['target_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# для нормализации данных используем ранк гаусс трансформацию. \n",
    "# импортнем библеотеку и добавим путь к ней \n",
    "#!git clone https://github.com/aldente0630/gauss-rank-scaler\n",
    "sys.path.append('./gauss-rank-scaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# числовые переменные, которые подвергнем трансформации\n",
    "num_cols = [col for col in list(rides_df.columns)\n",
    "            if col not in ['target_1', 'target_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "scaler = GaussRankScaler()\n",
    "df = scaler.fit_transform(rides_df[num_cols])\n",
    "df = pd.DataFrame(df, columns=num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_scaler = GaussRankScaler()\n",
    "target = target_scaler.fit_transform(rides_df['target_1'].values.reshape(-1, 1))\n",
    "df['target_1'] = target\n",
    "df['target_class'] = rides_df['target_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ВАЖНО! - фиксируем воспроизводимость\n",
    "def seed_everything(seed=42):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# для наших данных и размера нейросети подойдет запуск на cpu\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраняем гиперпараметры в виде словаря, для того чтобы позже зарегистрировать этот конфигурационный файл в W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Определяем гиперпараметры\u001b[39;00m\n\u001b[1;32m      3\u001b[0m CONFIG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m (\n\u001b[1;32m      4\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      5\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      6\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[1;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      8\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mcpu_count(),\n\u001b[1;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m---> 10\u001b[0m     num_features\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m# кол-во фичей подаваемое на вход\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     num_tar_2\u001b[38;5;241m=\u001b[39mtrain\u001b[38;5;241m.\u001b[39mtarget_class\u001b[38;5;241m.\u001b[39mnunique(), \u001b[38;5;66;03m# количество выходов равно кол-ву предсказываемых классов\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     architecture \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     infra \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKaggle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# Определяем гиперпараметры\n",
    "\n",
    "CONFIG = dict (\n",
    "    hidden_size=128,\n",
    "    dropout=0.1,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    num_workers=os.cpu_count(),\n",
    "    epochs=10,\n",
    "    num_features=train.shape[1]-2, # кол-во фичей подаваемое на вход\n",
    "    num_tar_2=train.target_class.nunique(), # количество выходов равно кол-ву предсказываемых классов\n",
    "    architecture = \"MLP\",\n",
    "    infra = \"Kaggle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Строим входной конвейер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# датасет выдает фичи и значения целевых переменных\n",
    "class Rides(Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx,:]\n",
    "        \n",
    "        data = row.drop(labels=['target_1', 'target_class'])\n",
    "        \n",
    "        data = torch.FloatTensor(data.values.astype('float'))\n",
    "        tar_1 = torch.tensor(row['target_1']).float()\n",
    "        tar_2 = row['target_class'].astype('int')\n",
    "        \n",
    "        return data, tar_1, tar_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build data loaders\n",
    "\n",
    "train_datasets = {'train': Rides(train),\n",
    "                  'val': Rides(test)}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(train_datasets[x], \n",
    "                                                   batch_size=CONFIG['batch_size'], \n",
    "                                                   shuffle=True, \n",
    "                                                   num_workers=CONFIG['num_workers'])\n",
    "                    for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настраиваем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Построим архитектуру mlp с двумя головами для регрессии и классифкации\n",
    "\n",
    "class TabularNN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "                          nn.Linear(cfg['num_features'], cfg['hidden_size']),\n",
    "                          nn.Dropout(cfg['dropout']),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(cfg['hidden_size'], cfg['hidden_size']),\n",
    "                          nn.Dropout(cfg['dropout']),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(cfg['hidden_size'], cfg['hidden_size'] // 2),\n",
    "                          )\n",
    "        \n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(cfg['hidden_size'] // 2, 1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(cfg['hidden_size'] // 2, cfg['num_tar_2'])\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.mlp(data)\n",
    "        tar1 = self.regressor(x)\n",
    "        tar2 = self.classifier(x)\n",
    "        return tar1.view(-1), tar2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем и логируем результаты в W&B\n",
    "\n",
    "В этом разделе будем использовать:\n",
    "\n",
    "* [`wandb.init()`](https://docs.wandb.ai/guides/track/launch): инициализировать новый запуск.\n",
    "* [`wandb.finish()`](https://docs.wandb.ai/ref/python/finish):  завершить и закрыть пробег.\n",
    "* [`wandb.config`](https://docs.wandb.ai/guides/track/config): объект, в котором хранятся гиперпараметры и настройки, связанные с запуском.\n",
    "\n",
    "\n",
    "Run (или [объект wandb.Run](https://docs.wandb.ai/ref/python/run)) - это единица вычисления W&B, обычно это 1 эксперимент обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = TabularNN(CONFIG).to(device)\n",
    "\n",
    "# оптимайзер и лоссы для регрессии и классификации\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = CONFIG['lr'])\n",
    "regression_criterion = nn.MSELoss().to(device)\n",
    "classification_criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используем `wandb.init ()` для инициализации нового прогона W&B.\n",
    "\n",
    "В \"pipeline\" машинного обучения вы можете добавить `wandb.init ()` в начало обучающего сценария, а также сценарий оценки, и каждая часть будет отслеживаться как запуск в W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Добавим в CONFIG имя модели\n",
    "CONFIG['model_name'] = 'Tabular_NN'\n",
    "print('Training configuration: ', CONFIG)\n",
    "\n",
    "# Initialize W&B run\n",
    "run = wandb.init(project='Course contest',\n",
    "                 entity=\"ivanich\",\n",
    "                 config=CONFIG,\n",
    "                 group='MLP', \n",
    "                 job_type='train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ипользуемые аргументы `wandb.init ()`:\n",
    "\n",
    "* `project`: этот аргумент указывает имя проекта W&B, в который отправляется запуск. Создаем на платформе W&B новый проект с названием «CDSC_DataFeeling_contest» и одновременно отправляем в него run.\n",
    "\n",
    "* `config`: этот аргумент устанавливает `wandb.config`, объект, подобный словарю, в котором хранятся гиперпараметры, параметры ввода и другие независимые переменные.\n",
    "\n",
    "* `group`: этот аргумент указывает значение для группировки отдельных прогонов, чтобы было легче сравнивать прогоны из разных архитектур.\n",
    "\n",
    "* `job_type`: этот аргумент указывает тип выполнения, например, «`train`» или «`evaluate`». Установка типа run упрощает последующую фильтрацию и группировку run, например, чтобы сравнить несколько «`train`» run-ов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обновляем `wandb.config` \n",
    "\n",
    "Сохранение конфигурации тренировки полезно для анализа экспериментов и воспроизведения вашей работы позже. С помощью W&B вы также можете группировать run-ы по значениям конфигурации, что означает, что вы можете сравнивать настройки разных run-ов и видеть, как они влияют на результат.\n",
    "\n",
    "Есть несколько способов настроить `wandb.config`:\n",
    "\n",
    "* Задать `wandb.config` с аргументом `wandb.init (config)`, как указано выше.\n",
    "* Установить `wandb.config` напрямую.\n",
    "* См. Дополнительные параметры настройки в этом [Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Configs_in_W%26B.ipynb#scrollTo=xFf3zjBSixC1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add \"type\" and \"kaggle_competition\" to `wandb.config` directly\n",
    "wandb.config.type = 'baseline'\n",
    "wandb.config.kaggle_competition = 'Competitive Data Science Course by Data Feeling'\n",
    "\n",
    "# Close W&B run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проведем серию из 5 экспериментов для подбора параметра `dropout rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Изменим CONFIG - определим dropout как рандомную величину в заданном диапазоне значений\n",
    "import random\n",
    "\n",
    "CONFIG['dropout'] = random.uniform(0.01, 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = CONFIG['epochs']\n",
    "for _ in range(5):\n",
    "    # 🐝 initialise a wandb run\n",
    "    wandb.init(project='Course contest',\n",
    "                 entity=\"ivanich\", \n",
    "                config=CONFIG,\n",
    "                group='MLP', \n",
    "                job_type='train'\n",
    "            )\n",
    "    \n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100000.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels_1, labels_2 in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels_1 = labels_1.to(device)\n",
    "                labels_2 = labels_2.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "\n",
    "                    outputs_1, outputs_2 = model(inputs)\n",
    "                    loss_1 = regression_criterion(outputs_1, labels_1)\n",
    "                    loss_2 = classification_criterion(outputs_2, labels_2)\n",
    "\n",
    "                    loss = loss_1 + loss_2\n",
    "\n",
    "                    _, preds_2 = torch.max(outputs_2, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                val_acc_history.append(running_loss)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "            # 🐝 Log train and validation metrics to wandb\n",
    "            wandb.log({'{} loss'.format(phase): epoch_loss})\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # 🐝 Close your wandb run \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Используйте `run.finish ()`, чтобы закрыть инициализированный run W&B после завершения `job_type`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Каждый run получает свою собственную страницу, на вкладках которой содержится дополнительная информация о запуске.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание артефакта W&B.\n",
    "\n",
    "W&B Artifacts позволяет вам регистрировать данные, которые входят (например, набор данных) и выходят (например, веса обученной модели) этих процессов.\n",
    "\n",
    "Другими словами, артефакты - это способ сохранить ваши наборы данных и модели. Вы можете использовать [этот Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W%26B_Artifacts.ipynb), чтобы узнать больше об артефактах.\n",
    "\n",
    "### Сохраняем свою работу с помощью `wandb.log_artifact ()` \n",
    "\n",
    "В run есть три шага для создания и сохранения артефакта модели.\n",
    "\n",
    "1. Создайте пустой артефакт с помощью `wandb.Artifact ()`.\n",
    "2. Добавьте файл модели в Артефакт с помощью `wandb.add_file ()`.\n",
    "3. Вызовите `wandb.log_artifact ()`, чтобы сохранить Артефакт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'tab_model.pth')\n",
    "\n",
    "# Initialize a new W&B run\n",
    "run = wandb.init(project='Course contest',\n",
    "                 entity=\"ivanich\", \n",
    "                config=CONFIG,\n",
    "                group='MLP', \n",
    "                 job_type='save') # Note the job_type\n",
    "\n",
    "# Update `wandb.config`\n",
    "wandb.config.type = 'baseline'\n",
    "wandb.config.kaggle_competition = 'Competitive Data Science Course by Data Feeling'\n",
    "\n",
    "# Save model as Model Artifact\n",
    "artifact = wandb.Artifact(name='best_tab_NN', type='model') # Задаем произвольное имя\n",
    "artifact.add_file('tab_model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "# Finish W&B run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь залогируем бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import json\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mivanich\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/storage/Aleron/Course/Competitive_Data_Science/notebooks/wandb/run-20230419_100557-nldo4dwo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ivanich/Course%20contest/runs/nldo4dwo' target=\"_blank\">honest-hill-15</a></strong> to <a href='https://wandb.ai/ivanich/Course%20contest' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ivanich/Course%20contest' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ivanich/Course%20contest/runs/nldo4dwo' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest/runs/nldo4dwo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='Course contest',\n",
    "                 entity=\"ivanich\",\n",
    "                 job_type='train-model',\n",
    "                 group='XGB',\n",
    "                 config={'wandb_nb':'wandb_course_contest'})  # config is optional here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_params = {\n",
    "         'gamma': 1,               ## def: 0\n",
    "         'learning_rate': 0.1,     ## def: 0.1\n",
    "        'max_depth': 3,\n",
    "        'min_child_weight': 100,  ## def: 1\n",
    "        'n_estimators': 25,\n",
    "        'nthread': 4,\n",
    "        'random_state': 42,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 0,          ## def: 1\n",
    "        'eval_metric': [ 'mlogloss'],\n",
    "        'tree_method': 'hist'  # use `gpu_hist` to train on GPU\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.config.update(dict(bst_params))\n",
    "run.config.update({'early_stopping_rounds': 40})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_class\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X = df.drop(['target_1','target_class'], axis=1)\n",
    "y = df['target_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `wandb` есть встроенная поддержка библиотеки XGBoost через callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.xgboost import wandb_callback\n",
    "\n",
    "# Initialize the XGBoostClassifier\n",
    "xgbmodel = xgboost.XGBClassifier(**bst_params, use_label_encoder=False)\n",
    "\n",
    "# Train the model, using the wandb_callback for logging\n",
    "xgbmodel.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "             early_stopping_rounds=run.config['early_stopping_rounds'])\n",
    "             callbacks=[wandb_callback()])\n",
    "\n",
    "bstr = xgbmodel.get_booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the booster to disk\n",
    "model_name = f'{run.name}_model.json'\n",
    "bstr.save_model(model_name)\n",
    "\n",
    "# Get the booster's config\n",
    "config = json.loads(bstr.save_config())\n",
    "\n",
    "# Log the trained model to W&B Artifacts, including the booster's config\n",
    "model_art = wandb.Artifact(name=model_name, type='model', metadata=dict(config))\n",
    "model_art.add_file(model_name)\n",
    "run.log_artifact(model_art);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log booster metrics\n",
    "run.summary[\"best_score\"] = bstr.best_score\n",
    "run.summary[\"best_iteration\"] = bstr.best_iteration\n",
    "run.summary[\"best_ntree_limit\"] = bstr.best_ntree_limit\n",
    "\n",
    "# Log validation metrics\n",
    "preds = xgbmodel.predict(X_test)\n",
    "run.summary[\"f1_score\"] = f1_score(y_test, preds, average='macro')\n",
    "run.summary[\"accuracy\"] = accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finish the W&B Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❄️ Ресурсы\n",
    "\n",
    "Вот несколько релевантных ссылок по теме:\n",
    "\n",
    "\n",
    "* Ознакомьтесь с [официальной документацией](https://docs.wandb.ai/), чтобы узнать больше о передовых методах работы и дополнительных функциях.\n",
    "\n",
    "* Ознакомьтесь с [репозиторием GitHub с примерами](https://github.com/wandb/examples), где вы найдете тщательно отобранные и минимальные примеры. Это может быть хорошей отправной точкой.\n",
    "\n",
    "Вот некоторые другие Kaggle ноутбуки с использованием Weights & Biases, которые могут быть вам полезны.\n",
    "\n",
    "* [EfficientNet+Mixup+K-Fold using TF and wandb](https://www.kaggle.com/ayuraj/efficientnet-mixup-k-fold-using-tf-and-wandb)\n",
    "\n",
    "* [HPA: Segmentation Mask Visualization with W&B](https://www.kaggle.com/ayuraj/hpa-segmentation-mask-visualization-with-w-b)\n",
    "\n",
    "* [HPA: Multi-Label Classification with TF and W&B](https://www.kaggle.com/ayuraj/hpa-multi-label-classification-with-tf-and-w-b)\n",
    "\n",
    "* [🐦BirdCLEF: Quick EDA with W&B](https://www.kaggle.com/ayuraj/birdclef-quick-eda-with-w-b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
